{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 机器学习基础\n",
    "\n",
    "机器学习可以分为监督学习(Supervised Learning)和非监督学习(Unsupervised Learning)，其中，监督学习又有两类任务：回归和分类。\n",
    "\n",
    "### 2.1.1 线性回归\n",
    "\n",
    "线性回归是处理回归任务的最简单模型，对于简单线性回归来说，我们可以作出如下假设：\n",
    "\n",
    "$$h_\\theta(x^{(i)})=\\theta _0 + \\theta _1x^{(i)}$$\n",
    "\n",
    "其中的$\\theta _0$和$\\theta_1$代表模型的参数。线性回归的目标是求得最适合的$\\theta _0$和$\\theta _1$使得模型效果最好。\n",
    "\n",
    "**数据集**\n",
    "\n",
    "我们通常收集一系列的真实数据，例如多栋房屋的真实售出价格和它们对应的面积。我们希望在这个数据上面寻找模型参数来使模型的预测价格与真实价格的误差最小。在机器学习术语里，该数据集被称为训练数据集（training data set）或训练集（training set），一栋房屋被称为一个样本（sample），其真实售出价格叫作标签（label），用来预测标签的两个因素叫作特征（feature）。特征用来表征样本的特点。\n",
    "\n",
    "**代价函数（损失函数）**\n",
    "\n",
    "衡量模型效果好坏的函数叫代价函数(Cost Function)，其中，均方误差(Mean Squared Error)是最简单的代价函数。\n",
    "\n",
    "均方误差就是求预测值与真实值之间的差值的平方，即：\n",
    "\n",
    "$$J(\\theta)=\\frac{1}{2m}\\sum^m_{i=1}(h_{\\theta}(x^{(i)})-y^{(i)})^2$$\n",
    "\n",
    "**梯度下降**\n",
    "\n",
    "我们的目标是找到合适的参数$\\theta$，使代价函数最小。因为梯度的反方向是函数值减小最快的方向，故我们更新自变量的策略为：\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\theta _j &= \\theta _j - \\alpha \\frac{\\partial }{\\partial \\theta _j}J(\\theta) \\\\\n",
    "          &=\\theta _j - \\alpha\\frac{1}{m}\\sum^m_{i=1}(h_\\theta (x^{(i)})-y^{(i)}x_j^{(i)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "其中$\\alpha$是学习率，即参数更新的步长，$\\frac{\\partial }{\\partial \\theta _j}J(\\theta) = \\frac{1}{m}\\sum^m_{i=1}(h_\\theta (x^{(i)})-y^{(i)})x_j^{(i)}$\n",
    "\n",
    "**例子：线性回归检测指针读数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def extract_red(image):\n",
    "    red_lower1 = np.array([0, 43, 46])\n",
    "    red_upper1 = np.array([10, 255, 255])\n",
    "    red_lower2 = np.array([156, 43, 46])\n",
    "    red_upper2 = np.array([180, 255, 255])\n",
    "    dst = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask1 = cv2.inRange(dst, lowerb=red_lower1, upperb=red_upper1)\n",
    "    mask2 = cv2.inRange(dst, lowerb=red_lower2, upperb=red_upper2)\n",
    "    mask = cv2.add(mask1, mask2)\n",
    "    return mask\n",
    "\n",
    "img = cv2.imread('../images/clock.png')  # 原图\n",
    "img = cv2.resize(img, (250, 250))\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img[:, :, ::-1])  # opencv BGR, RGB\n",
    "mask = extract_red(img)  # 提取红色\n",
    "plt.subplot(122)\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.argwhere(mask==255)[:, 1]\n",
    "Y = np.abs(mask.shape[0] - np.argwhere(mask==255)[:, 0])\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model      # 引入线性回归方法\n",
    "lin_reg = linear_model.LinearRegression()       # 创建线性回归的类\n",
    "X1 = X.reshape(-1, 1)\n",
    "lin_reg.fit(X1,Y)  # 输入特征X和因变量y进行训练\n",
    "print(\"模型系数：\",lin_reg.coef_)  # 输出模型的系数\n",
    "print(\"模型得分：\",lin_reg.score(X1,Y))  # 输出模型的决定系数R^2\n",
    "print(\"模型偏置：\", lin_reg.intercept_)  # 输出模型偏置b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由sklearn拟合出的直线为：$y = 0.43 x + 73$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "# y = kx + b\n",
    "\n",
    "iters = 3000\n",
    "k = 1\n",
    "b = 1\n",
    "lr = 0.00005\n",
    "size = X.shape[0]\n",
    "for epoch in range(iters):\n",
    "    y_pred = k * X + b\n",
    "    loss = np.mean((y_pred - Y) ** 2)\n",
    "    k = k - (lr/size) * np.dot(y_pred - Y, X.T)\n",
    "    b = b - 10000 * (lr/size) * np.sum(y_pred - Y)\n",
    "    if epoch % 10 == 0:\n",
    "        display.clear_output(wait=True)\n",
    "        x_line = np.linspace(100, 200, 1000)\n",
    "        y_line = k * x_line + b\n",
    "        plt.plot(x_line, y_line, 'r')\n",
    "        plt.title(f\"epoch:{epoch}, k:{round(k, 3)}, b:{round(b, 3)}, loss:{round(loss, 3)}\")\n",
    "        plt.xlim(100, 200)\n",
    "        plt.ylim(100, 160)\n",
    "        plt.scatter(X, Y)\n",
    "        plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 逻辑回归\n",
    "\n",
    "逻辑回归虽然名字中有“回归”，但其实际上是分类模型，并常用于二分类。首先我们定义sigmoid函数为：\n",
    "\n",
    "$$\\begin{equation}\n",
    "y = \\frac{1}{1+e^{-x}}\n",
    "\\end{equation}$$\n",
    "\n",
    "其定义域为：$(-\\infty, +\\infty)$,值域为：$(0, 1)$,导数为：$y'=y(1-y)$\n",
    "\n",
    "假设我们的模型为：\n",
    "\n",
    "$$h_{\\theta}(x)=\\frac{1}{1+e^{-\\theta ^ T x}}$$\n",
    "\n",
    "其中$x:[1 , x_1 , x_2]^T \\qquad \\theta:[b, w_1, w_2]^T$\n",
    "\n",
    "逻辑回归的代价函数与线性回归不同，其主要方法是极大似然估计。其推导如下：\n",
    "\n",
    "设$p\\{y=1|x;\\theta\\} = h_{\\theta}(x)$，设$p\\{y=0|x;\\theta\\} = 1- h_{\\theta}(x)$\n",
    "\n",
    "则似然函数：$L=\\prod^m_{i=1}p^{(i)} = \\prod ^m_{i=1}h_{\\theta}^{y^{(i)}}(x^{(i)})(1-h_{\\theta}(x^{(i)}))^{1-y^{(i)}}$\n",
    "\n",
    "两边取对数：$log(L) = \\sum^m_{i=1}\\{y^{(i)}logh_{\\theta}(x^{(i)})+(1-y^{(i)})log[1-h_{\\theta}(x^{(i)})]\\}$\n",
    "\n",
    "我们的目标是使L最大，即事件发生概率最大，所以定义代价函数如下：\n",
    "\n",
    "$$J(\\theta)=-\\frac{1}{m}\\sum^{m}_{i=1}\\left[y^{(i)}log(h_{\\theta}(x^{(i)})) + (1-y^{(i)})log(1-h_\\theta (x^{(i)}))\\right]$$\n",
    "\n",
    "逻辑回归梯度下降：\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\theta} = - \\frac{1}{m} \\sum ^m _{i=1}[y^{(i)}\\frac{\\frac{\\partial h_{\\theta}(x^{(i)})}{\\partial \\theta}}{h_{\\theta (x^{(i)})}} + (1-y^{(i)})\\frac{\\frac{\\partial h_{\\theta}(x^{(i)})}{\\partial \\theta}}{1-h_{\\theta (x^{(i)})}}]$$\n",
    "\n",
    "其中$\\frac{\\partial h(x)}{\\partial \\theta} = [h(x)[1-h(x)]x_j]$,代入上式化简可得：\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\theta} = \\frac{1}{m}\\sum^m_{i=1}(h_\\theta (x^{(i)})-y^{(i)})x_j^{(i)}$$\n",
    "\n",
    "逻辑回归一般解决二分类问题，当遇到多分类时，通常有两种方法：\n",
    "\n",
    "- 一对多：\n",
    "\n",
    "例如现在有三个类别：A,B,C，我们可以训练一个模型分出A与B,C，另一个模型分出B与A,C，最后一个模型分出C与A,B\n",
    "\n",
    "优点：需要训练的模型较少\n",
    "\n",
    "缺点：样本不均衡\n",
    "\n",
    "- 一对一：\n",
    "\n",
    "假如需要分k类，我们需要训练$C^2_k$个模型，即每两个类训练一个模型\n",
    "\n",
    "优点：数据少、样本均衡\n",
    "\n",
    "缺点：需要训练的模型较多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 创建数据集\n",
    "np.random.seed(1115)\n",
    "\n",
    "data_0 = np.random.multivariate_normal(mean=[3, 4], cov=[[3, 0], [0, 1]], size=100)  # 第0类:100个样本\n",
    "data_1 = np.random.multivariate_normal(mean=[7, 6], cov=[[3, 0], [0, 2]], size=200)  # 第1类:200个样本\n",
    "data_x = np.vstack((data_0, data_1))\n",
    "data_y = np.hstack((np.array([0]*100), np.array([1]*200)))\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(data_x, data_y))  # 将x，y打包\n",
    "random.shuffle(data)  # 打乱\n",
    "data_x, data_y = zip(*data)  # 解包\n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(y_pred, data_y):\n",
    "    return -np.mean(data_y*np.log(y_pred) + (1-data_y)*np.log(1-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(y_pred, data_y):\n",
    "    return np.mean((y_pred >= 0.5) == data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iters = 3000\n",
    "w1 = 1\n",
    "w2 = 1\n",
    "b = 1\n",
    "lr = 0.1\n",
    "size = data_x.shape[0]\n",
    "for epoch in range(iters):\n",
    "    y_pred = sigmoid(w1*data_x[:, 0] + w2*data_x[: ,1] + b)\n",
    "    loss = cal_loss(y_pred, data_y)\n",
    "    w1 = w1 - (lr/size) * np.dot((y_pred - data_y), data_x[:, 0].T)\n",
    "    w2 = w2 - (lr/size) * np.dot((y_pred - data_y), data_x[:, 1].T)\n",
    "    b = b - (lr/size) * np.sum(y_pred - data_y)\n",
    "    if epoch % 100 == 0 :\n",
    "        display.clear_output(wait=True)\n",
    "        line_x = np.linspace(-5, 15, 1000)\n",
    "        line_y = (-b-w1*line_x)/w2\n",
    "        plt.xlim(-5, 15)\n",
    "        plt.ylim(-5, 15)\n",
    "        plt.plot(line_x, line_y)\n",
    "        plt.title(f'epoch:{epoch}, loss:{round(loss, 3)}, w1:{round(w1 ,3)}, w2:{round(w2, 3)}, b:{round(b, 3)}, acc:{round(cal_acc(y_pred, data_y), 3)}')\n",
    "        plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y)\n",
    "        plt.savefig('lr.jpg')\n",
    "        plt.show()\n",
    "        plt.pause(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sklean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(data_x, data_y)\n",
    "\n",
    "\n",
    "print(model.coef_)  # 输出模型的系数\n",
    "print(model.intercept_)  # 输出模型偏置b\n",
    "print(model.score(data_x, data_y))  # 输出模型准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 神经网络（Neural Network）\n",
    "\n",
    "#### 2.1.3.1 为什么需要神经网络?\n",
    "\n",
    "与前面介绍的线性回归和逻辑回归不同，神经网络通常解决非线性问题，如下图（上）所示的非线性回归问题和下图（下）所示的非线性分类问题：\n",
    "\n",
    "<div align=center><img width=\"60%\" height=\"60%\" src=\"../images/regression.png\"></div>\n",
    "\n",
    "<div align=center><img width=\"60%\" height=\"60%\" src=\"../images/classification.png\"></div>\n",
    "\n",
    "线性回归和逻辑回归就不能很好地处理这两种问题。\n",
    "\n",
    "#### 2.1.3.1 什么是神经网络?\n",
    "\n",
    "神经网络的基本结构如下图所示：\n",
    "\n",
    "<div align=center><img width=\"60%\" height=\"60%\" src=\"../images/NN.jpg\"></div>\n",
    "\n",
    "设输入为x维，隐藏层为h维，输出为y维，激活函数为g(x)\n",
    "\n",
    "- 输入层\n",
    "\n",
    "输入层维度数就是样本的特征数，例如一个二维坐标有两个特征：x和y，所以输入层为二维；一张32$\\times$32的图片有$32^2$个特征，故输入层的维度数为$32^2$\n",
    "\n",
    "- 输入层到隐藏层\n",
    "\n",
    "输入层到隐藏层其实就是h个线性回归模型，表达式为：\n",
    "\n",
    "$$H_{(1 \\times h)}=X_{(1 \\times x)} \\cdot W_{1(x \\times h)} + b_{1(1 \\times h)}$$\n",
    "\n",
    "- 激活层\n",
    "\n",
    "简而言之，激活层是为矩阵运算的结果添加非线性的。常用的激活函数有Sigmoid、Tanh和ReLU。\n",
    "它们的函数图像如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 100)\n",
    "y1 = 1/(1+np.exp(-x))\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(131)\n",
    "plt.plot(x, y1)\n",
    "plt.title('Sigmoid')\n",
    "plt.savefig('sigmoid.jpg')\n",
    "plt.subplot(132)\n",
    "y2 = np.tanh(x)\n",
    "plt.plot(x, y2)\n",
    "plt.title('Tanh')\n",
    "plt.subplot(133)\n",
    "y3 = list(map(lambda x:x if x > 0 else 0, x))\n",
    "plt.plot(x, y3)\n",
    "plt.title('ReLU')\n",
    "plt.savefig('activation.jpg', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 从隐藏层到输出层\n",
    "\n",
    "连接隐藏层和输出层的是$W_2$和$b_2$。同样是通过矩阵运算进行的：\n",
    "\n",
    "$$Y = H \\cdot W_2+b_2$$\n",
    "\n",
    "- Softmax\n",
    "\n",
    "假设有一个数组Y，$Y_i$表示$Y$中的第$i$个元素，那么这个元素的Softmax值为：\n",
    "\n",
    "$$S_i=\\frac{e^{z_i}}{\\sum _{j=1}^y e^{z_j}}$$\n",
    "\n",
    "该元素的softmax值，就是该元素的指数与所有元素指数和的比值。但是如果$z$的值很大时，会出现数据溢出的情况，优化版的softmax可以防止这种情况，其表达式如下：\n",
    "\n",
    "$$S_i=\\frac{e^{z_i-max(z)}}{\\sum _{j=1}^y e^{z_j-max(z)}}$$\n",
    "\n",
    "- 交叉熵损失函数\n",
    "\n",
    "$$J(\\theta) = - \\frac{1}{m}\\sum ^m_{i=1}\\sum^C_{c=1}y_c^ilnp^i_c $$\n",
    "\n",
    "对于分类任务来说，$y = (0, 0, \\cdots, 1, \\cdots, 0)^T$，设第$k$个元素为1，则：\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum^m_{i=1} ln p_k^i$$\n",
    "\n",
    "其中$p_i = \\frac{e^{z_k}}{\\sum e^{z_j}},\\qquad$\n",
    "\n",
    "#### 2.1.3.3 怎么实现神经网络?\n",
    "\n",
    "神经网络最核心的部分就是bp算法，其主要思想就是高数中的复合函数求导，下面举一个简单的例子：\n",
    "\n",
    "<div align=center><img width=\"60%\" height=\"60%\" src=\"../images/chain.png\"></div>\n",
    "\n",
    "$$ 其中，\\left\\{\n",
    "\\begin{aligned}\n",
    "c & =  a+b \\\\\n",
    "d & =  b +1 \\\\\n",
    "e & =  c \\times d\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "$$ 故，\\left\\{\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial e}{\\partial d} & = c \\\\\n",
    "\\frac{\\partial e}{\\partial c} & = d \\\\\n",
    "\\frac{\\partial e}{\\partial b} & = \\frac{\\partial e}{\\partial d}\\frac{\\partial d}{\\partial b} +\\frac{\\partial e}{\\partial c}\\frac{\\partial c}{\\partial b} = d +c = a + 2b +1\\\\\n",
    "\\frac{\\partial e}{\\partial a} & = \\frac{\\partial e}{\\partial d}\\frac{\\partial d}{\\partial a} +\\frac{\\partial e}{\\partial c}\\frac{\\partial c}{\\partial a} = d = b +1\\\\\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面完整推导一次神经网络的反向传播：\n",
    "\n",
    "|变量|含义|\n",
    "|--|--|\n",
    "|x|输入样本|\n",
    "|h|第一层输出|\n",
    "|a|对第一层输出激活|\n",
    "|z|第二层输出|\n",
    "|p|对第二层输出进行softmax|\n",
    "|L|对p求损失|\n",
    "|w1|第一层权重|\n",
    "|w2|第二层权重|\n",
    "|b1|第一层偏置|\n",
    "|b2|第二层偏置|\n",
    "|y|标签|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里以一个样本为例：\n",
    "设$y = (0, 0, \\cdots, 1, \\cdots, 0)^T$，其中第k个元素为1\n",
    "1. softmax - loss \n",
    "$$L = -lnp_k$$\n",
    "$$\\frac{\\partial L_k}{\\partial p_i} = \\left\\{\n",
    "\\begin{aligned}\n",
    "& -\\frac{1}{p_k} &i=k\\\\\n",
    "& 0 &i \\neq k\n",
    "\\end{aligned}\n",
    "\\right.$$\n",
    "\n",
    "\n",
    "\n",
    "2. z - softmax\n",
    "\n",
    "$$p_i = \\frac{e^{z_i}}{\\sum _j e^{z_j}}$$\n",
    "当$i=k$时\n",
    "\n",
    "$$\\frac{\\partial p_k}{\\partial z_k} = \\frac{\\sum_j e^{z_j} e^{z_k} - e^{z_k}e^{z_k}}{(\\sum_j e^{e_j})^2} = p_k(1-p_k)$$\n",
    "\n",
    "此时，$\\frac{\\partial L_k}{\\partial z_k} = p_k - 1$\n",
    "\n",
    "当$i \\not= k $时\n",
    "\n",
    "$$\\frac{\\partial p_k}{\\partial z_i} = -\\frac{e^{z_k}e^{z_i}}{(\\sum_j e^{e_j})^2} = -p_kp_i$$\n",
    "\n",
    "此时，$\\frac{\\partial L_k}{\\partial z_i} = p_i$\n",
    "\n",
    "前面几层参考线性回归即可，至此，神经网络全部介绍完了，下面用代码实现一下\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorbay import GAS\n",
    "from tensorbay.dataset import Segment\n",
    "\n",
    "# Authorize a GAS client.\n",
    "gas = GAS('Accesskey-dac95e0d8e685ef4d5f8b80d51e38499')\n",
    "\n",
    "# Get a dataset client.\n",
    "dataset_client = gas.get_dataset(\"FashionMNIST-PyTorch\")\n",
    "\n",
    "# List dataset segments.\n",
    "segments = dataset_client.list_segment_names()\n",
    "\n",
    "# Get a segment by name\n",
    "segment = Segment(\"data\", dataset_client)\n",
    "for data in segment:\n",
    "    with open(\"FashionMNIST.zip\", \"wb\") as fp:\n",
    "        fp.write(data.open().read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch import save\n",
    "\n",
    "mnist_train = datasets.FashionMNIST(root='.', train=True, download=False, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.FashionMNIST(root='.', train=False, download=False, transform=transforms.ToTensor())\n",
    "train_iter = DataLoader(mnist_train, batch_size=64, shuffle=True, num_workers=0)\n",
    "test_iter = DataLoader(mnist_test, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "print(mnist_train.data[0].shape)  # 图片大小\n",
    "print(mnist_train.targets.unique())  # 标注信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fashion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Fashion, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(28*28, 1024),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(1024, 10))\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        y = self.net(x)\n",
    "        return y\n",
    "    \n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    test_acc =[]\n",
    "    for X, y in data_iter:\n",
    "        test_acc.append((net(X).argmax(dim=1) == y).float().sum().item() / y.shape[0])\n",
    "    return np.mean(test_acc)\n",
    "\n",
    "epochs = 5\n",
    "net = Fashion()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for epoch in range(epochs):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    for x, y in train_iter:\n",
    "        y_pred = net(x)\n",
    "        loss = criterion(y_pred, y).sum()\n",
    "\n",
    "        loss.backward()  # \n",
    "        optimizer.step()  \n",
    "        train_loss.append(loss.item())\n",
    "        train_acc.append((y_pred.argmax(dim=1)==y).sum().item() / y.shape[0])\n",
    "    test_acc = evaluate_accuracy(test_iter, net)    \n",
    "    print(f'epoch:{epoch} train_loss:{np.mean(train_loss)} train_acc:{np.mean(train_acc)} test_acc:{test_acc}')\n",
    "\n",
    "save(net.state_dict(), 'last.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线上训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch import save\n",
    "\n",
    "from tensorbay import GAS\n",
    "from tensorbay.dataset import Dataset as TensorBayDataset\n",
    "\n",
    "\n",
    "class MNISTSegment(Dataset):\n",
    "    \"\"\"class for wrapping a MNIST segment.\"\"\"\n",
    "    def __init__(self, gas, segment_name, transform):\n",
    "        super().__init__()\n",
    "        self.dataset = TensorBayDataset(\"FashionMNIST-PyTorch\", gas)\n",
    "        self.segment = self.dataset[segment_name]\n",
    "        self.category_to_index = self.dataset.catalog.classification.get_category_to_index()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.segment)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.segment[idx]\n",
    "        with data.open() as fp:\n",
    "            image_tensor = self.transform(Image.open(fp))\n",
    "\n",
    "        return image_tensor, self.category_to_index[data.label.classification.category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY = \"Accesskey-dac95e0d8e685ef4d5f8b80d51e38499\"\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "normalization = transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "my_transforms = transforms.Compose([to_tensor, normalization])\n",
    "\n",
    "train_segment = MNISTSegment(GAS(ACCESS_KEY), segment_name=\"train\", transform=my_transforms)\n",
    "train_dataloader = DataLoader(train_segment, batch_size=4, shuffle=True)\n",
    "test_segment = MNISTSegment(GAS(ACCESS_KEY), segment_name=\"test\", transform=my_transforms)\n",
    "test_dataloader = DataLoader(test_segment, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▏                                                                         | 422/15000 [14:22<8:16:30,  2.04s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9d802f87eff5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-55c2e5f105c2>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mimage_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\site-packages\\tensorbay\\utility\\file.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \"\"\"\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquote\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprintable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[no-any-return]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'urllib.Request'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[0;32m    543\u001b[0m                                   '_open', req)\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1397\u001b[1;33m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[0;32m   1398\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0;32m   1399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1352\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1353\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1354\u001b[1;33m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[0;32m   1355\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1253\u001b[0m                 encode_chunked=False):\n\u001b[0;32m   1254\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1299\u001b[0m             \u001b[1;31m# default charset of iso-8859-1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1248\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m     def request(self, method, url, body=None, headers={}, *,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1008\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb\"\\r\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1415\u001b[0m             \u001b[1;34m\"Connect to a host on a given (SSL) port.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1417\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tunnel_host\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m         \u001b[1;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m         self.sock = self._create_connection(\n\u001b[0m\u001b[0;32m    922\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0;32m    923\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    785\u001b[0m     \u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maddress\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[0msock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    916\u001b[0m     \u001b[1;31m# and socket type values to enum constants.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m         addrlist.append((_intenum_converter(af, AddressFamily),\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class Fashion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Fashion, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(28*28, 1024),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(1024, 10))\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        y = self.net(x)\n",
    "        return y\n",
    "    \n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    test_acc =[]\n",
    "    for X, y in data_iter:\n",
    "        test_acc.append((net(X).argmax(dim=1) == y).float().sum().item() / y.shape[0])\n",
    "    return np.mean(test_acc)\n",
    "\n",
    "epochs = 5\n",
    "net = Fashion()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for epoch in range(epochs):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    for x, y in tqdm(train_dataloader):\n",
    "        y_pred = net(x)\n",
    "        loss = criterion(y_pred, y).sum()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        train_acc.append((y_pred.argmax(dim=1)==y).sum().item() / y.shape[0])\n",
    "    test_acc = evaluate_accuracy(test_dataloader, net)    \n",
    "    print(f'epoch:{epoch} train_loss:{np.mean(train_loss)} train_acc:{np.mean(train_acc)} test_acc:{test_acc}')\n",
    "save(net.state_dict(), 'last.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(torch171)",
   "language": "python",
   "name": "torch171"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
